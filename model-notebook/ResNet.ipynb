{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Air Quality Index (AQI) Prediction Based on AlexNet, VGGNet, ResNet\n",
    "\n",
    "Kelompok 01 Kecerdasan buatan 02:\n",
    "* Fateen Najib Indramustika - 2006468522\n",
    "* Joshevan - 2006577321\n",
    "* Airell Ramadhan Budiraharjo - 2006535230"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "load data from csv and image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir())\n",
    "os.chdir('/home/fateenindramustika/predict-air-quality-with-ANN')\n",
    "image_files = os.listdir('image-dataset')\n",
    "image_timestamps = [datetime.strptime(os.path.splitext(file)[0][0:15], \"%Y%m%d_%H%M%S\") for file in image_files]\n",
    "\n",
    "data = {'File Name': image_files, 'Timestamp': image_timestamps}\n",
    "df_image = pd.DataFrame(data)\n",
    "\n",
    "image_timestamps = [os.path.splitext(file)[0] for file in image_files]\n",
    "\n",
    "aqi_data = pd.read_csv('aqi-dataset/air_quality_data.csv')\n",
    "\n",
    "aqi_timestamps = aqi_data['Now Timestamp'].tolist()\n",
    "\n",
    "aqi_timestamps = [datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S.%f\") for timestamp in aqi_timestamps]\n",
    "\n",
    "data = {'Timestamp': aqi_timestamps, 'AQI': aqi_data['AQI']}\n",
    "df_aqi = pd.DataFrame(data)\n",
    "print(df_aqi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairing the data from CSV and image files\n",
    "match the data by checking the timestamp and find the air quality index based on the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(row, df, column='Timestamp'):\n",
    "    absolute_difference_function = lambda x: abs(x - row['Timestamp'])\n",
    "    nearest_timestamp = df[column].apply(absolute_difference_function).idxmin()\n",
    "    return df.loc[nearest_timestamp]\n",
    "\n",
    "nearest_aqi = df_image.apply(find_nearest, args=(df_aqi,), axis=1)\n",
    "\n",
    "df_image = pd.concat([df_image, nearest_aqi], axis=1)\n",
    "\n",
    "df_image.drop(columns=['Timestamp'], inplace=True)\n",
    "df_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data preprocessing\n",
    "preprocess the image data by resizing the image to 224x224 and normalize the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_image, test_size=0.2, random_state=42)\n",
    "train_datagen = ImageDataGenerator(rescale=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=0.2)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    directory='image-dataset/',\n",
    "    x_col='File Name',\n",
    "    y_col='AQI',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_data,\n",
    "    directory='image-dataset/',\n",
    "    x_col='File Name',\n",
    "    y_col='AQI',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building\n",
    "build the model using ResNet101 with custom output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1)(x) \n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error',tf.keras.metrics.RootMeanSquaredError(),r_squared])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "train the model using the image data and air quality index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_data) // 32,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_data) // 32,\n",
    "    epochs=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the model and history to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now(pytz.timezone('Asia/Jakarta'))\n",
    "\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "model.save(f'models/resnet_aqi_prediction_{timestamp}.h5')\n",
    "\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "\n",
    "hist_df.to_csv(f'histories/history_{timestamp}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "\n",
    "hist_df.to_csv(f'histories/history_{timestamp}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting the training metrics\n",
    "plot the training metrics collected from the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mae = history.history['val_root_mean_squared_error']\n",
    "mae = history.history['root_mean_squared_error']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(val_mae)\n",
    "plt.plot(mae)\n",
    "plt.title('RMSE over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend(['Validation RMSE', 'RMSE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mae = history.history['val_mean_absolute_error']\n",
    "mae = history.history['mean_absolute_error']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(val_mae)\n",
    "plt.plot(mae)\n",
    "plt.title('MAE over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(['Validation MAE', 'MAE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lost = history.history['val_loss']\n",
    "lost = history.history['loss']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(val_lost)\n",
    "plt.plot(lost)\n",
    "plt.title('Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Validation Loss', 'Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate the model using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_mae, test_rmse  = model.evaluate(test_generator, steps=len(test_data) // 32)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "print(f\"Test RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "\n",
    "df_result = pd.DataFrame({\n",
    "    'File Name': test_data['File Name'],\n",
    "    'Actual AQI': test_data['AQI'],\n",
    "    'Predicted AQI': predictions.flatten()\n",
    "})\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result.sort_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_result['Actual AQI'], label='Actual AQI')\n",
    "plt.plot(df_result['Predicted AQI'], label='Predicted AQI')\n",
    "plt.title('Actual AQI vs Predicted AQI')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('AQI')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
